{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3ee0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5379199",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dcb52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 10000\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "target_texts_input = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b03f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "\n",
    "with open(\"../neural_machine_translation/data/hin.txt\") as f:\n",
    "    for line in f:\n",
    "        \n",
    "        # keeping only limited number of samples\n",
    "        t += 1\n",
    "        if t > NUM_SAMPLES:\n",
    "            break\n",
    "            \n",
    "        if '\\t' not in line:\n",
    "            continue\n",
    "            \n",
    "        input_text, translation, *rest = line.rstrip().split('\\t')\n",
    "        \n",
    "        target_text = translation + ' <eos>'\n",
    "        target_text_input = '<sos> ' + translation\n",
    "        \n",
    "        input_texts.append(input_text)\n",
    "        target_texts.append(target_text)\n",
    "        target_texts_input.append(target_text_input)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b132a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> वाह!',\n",
       " '<sos> झुको!',\n",
       " '<sos> बतख़!',\n",
       " '<sos> बचाओ!',\n",
       " '<sos> उछलो.',\n",
       " '<sos> कूदो.',\n",
       " '<sos> छलांग.',\n",
       " '<sos> नमस्ते।',\n",
       " '<sos> नमस्कार।',\n",
       " '<sos> वाह-वाह!',\n",
       " '<sos> चियर्स!',\n",
       " '<sos> सांस छोड़।',\n",
       " '<sos> सांस छोड़ो।',\n",
       " '<sos> समझे कि नहीं?',\n",
       " '<sos> मैं ठीक हूँ।']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts_input[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd771c3",
   "metadata": {},
   "source": [
    "### Tokenizers and word to index mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd438f",
   "metadata": {},
   "source": [
    "#### I have two languages to deal with, hence need two different tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4649d19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wow!', 'Duck!', 'Duck!', 'Help!', 'Jump.']\n"
     ]
    }
   ],
   "source": [
    "print(input_texts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a12a2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 10:05:54.821064: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from itertools import islice\n",
    "\n",
    "MAX_NUM_WORDS = 20000\n",
    "MAX_SEQ_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3546e4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1326], [949], [949], [83], [582], [582], [582]]\n",
      "Found 2463 unique input tokens\n",
      "Maximum length of input sequences: 22\n"
     ]
    }
   ],
   "source": [
    "# tokenizer for inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "print(input_sequences[:7])\n",
    "\n",
    "\n",
    "# word_to_index mapping \n",
    "word_to_idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens' % len(word_to_idx_inputs))\n",
    "first_10_mapping_inputs = dict(islice(word_to_idx_inputs.items(), 10))\n",
    "first_10_mapping_inputs\n",
    "\n",
    "\n",
    "# maximum length of input sequences\n",
    "max_len_inputs = max(len(i) for i in input_sequences)\n",
    "print(\"Maximum length of input sequences:\",max_len_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4890242d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1538, 1], [1539, 1], [1540, 1], [1541, 1], [1542, 1]]\n",
      "[[2, 1538], [2, 1539], [2, 1540], [2, 1541], [2, 1542]]\n",
      "Found 3265 unique output tokens\n",
      "Maximum length of output sequences: 26\n"
     ]
    }
   ],
   "source": [
    "# tokenizer for outputs\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_input)\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_input)\n",
    "print(target_sequences[:5])\n",
    "print(target_sequences_inputs[:5])\n",
    "\n",
    "\n",
    "# word to index mapping\n",
    "word_to_idx_outputs = tokenizer_outputs.word_index\n",
    "print(\"Found %s unique output tokens\" % len(word_to_idx_outputs))\n",
    "first_10_mappings_outputs = dict(islice(word_to_idx_outputs.items(), 10))\n",
    "first_10_mappings_outputs\n",
    "\n",
    "\n",
    "# maximum length of output sequences\n",
    "max_len_outputs = max(len(i) for i in target_sequences)\n",
    "print(\"Maximum length of output sequences:\",max_len_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca488d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3266"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words_output = len(word_to_idx_outputs) + 1\n",
    "num_words_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85fe6d6",
   "metadata": {},
   "source": [
    "### Pad each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c9af77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input shape is (3061, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1326],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding for encoder inputs\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_inputs)\n",
    "print(\"Encoder input shape is\", encoder_inputs.shape)\n",
    "encoder_inputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db1eb7d",
   "metadata": {},
   "source": [
    "#### Upon seeing the encoder state/the last word of the input sequence, the decoder produces the output immediately rather than having to go through a bunch of zeros first, hence post padding for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61e58683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder input shape is (3061, 26)\n",
      "[   2 1538    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Decoder target shape is (3061, 26)\n",
      "[1538    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# padding for decoder inputs and targets\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_outputs, padding='post')\n",
    "print(\"Decoder input shape is\", decoder_inputs.shape)\n",
    "print(decoder_inputs[0])\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_outputs, padding='post')\n",
    "print(\"Decoder target shape is\", decoder_targets.shape)\n",
    "print(decoder_targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9f1c0",
   "metadata": {},
   "source": [
    "### Storing pre-trained vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a68fc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "print(\"Filling pre-trained embeddings...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69a38d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/saylinarkhede/Jupyter/github_/neural_machine_translation/glove'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() + '/glove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f4b9773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "word_to_vec = {}\n",
    "with open(os.path.join(os.getcwd() + '/glove/glove.6B.%sd.txt' %EMBEDDING_DIM)) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word_to_vec[word] = vec\n",
    "        \n",
    "print('Found %s word vectors' %len(word_to_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75abb600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector length is 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'the': array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "        -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "         0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "        -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "         0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "        -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "         0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "         0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "        -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "        -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "        -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "        -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "        -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "        -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "        -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "         0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "        -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32),\n",
       " ',': array([-0.10767  ,  0.11053  ,  0.59812  , -0.54361  ,  0.67396  ,\n",
       "         0.10663  ,  0.038867 ,  0.35481  ,  0.06351  , -0.094189 ,\n",
       "         0.15786  , -0.81665  ,  0.14172  ,  0.21939  ,  0.58505  ,\n",
       "        -0.52158  ,  0.22783  , -0.16642  , -0.68228  ,  0.3587   ,\n",
       "         0.42568  ,  0.19021  ,  0.91963  ,  0.57555  ,  0.46185  ,\n",
       "         0.42363  , -0.095399 , -0.42749  , -0.16567  , -0.056842 ,\n",
       "        -0.29595  ,  0.26037  , -0.26606  , -0.070404 , -0.27662  ,\n",
       "         0.15821  ,  0.69825  ,  0.43081  ,  0.27952  , -0.45437  ,\n",
       "        -0.33801  , -0.58184  ,  0.22364  , -0.5778   , -0.26862  ,\n",
       "        -0.20425  ,  0.56394  , -0.58524  , -0.14365  , -0.64218  ,\n",
       "         0.0054697, -0.35248  ,  0.16162  ,  1.1796   , -0.47674  ,\n",
       "        -2.7553   , -0.1321   , -0.047729 ,  1.0655   ,  1.1034   ,\n",
       "        -0.2208   ,  0.18669  ,  0.13177  ,  0.15117  ,  0.7131   ,\n",
       "        -0.35215  ,  0.91348  ,  0.61783  ,  0.70992  ,  0.23955  ,\n",
       "        -0.14571  , -0.37859  , -0.045959 , -0.47368  ,  0.2385   ,\n",
       "         0.20536  , -0.18996  ,  0.32507  , -1.1112   , -0.36341  ,\n",
       "         0.98679  , -0.084776 , -0.54008  ,  0.11726  , -1.0194   ,\n",
       "        -0.24424  ,  0.12771  ,  0.013884 ,  0.080374 , -0.35414  ,\n",
       "         0.34951  , -0.7226   ,  0.37549  ,  0.4441   , -0.99059  ,\n",
       "         0.61214  , -0.35111  , -0.83155  ,  0.45293  ,  0.082577 ],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "first_2_vecs = dict(islice(word_to_vec.items(), 2))\n",
    "print('Vector length is', len(list(first_2_vecs.items())[0][1]))\n",
    "first_2_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6607ffd",
   "metadata": {},
   "source": [
    "### Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a17982a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2478b220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(word_to_idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros(shape=(num_words, EMBEDDING_DIM))\n",
    "embedding_matrix.shape\n",
    "\n",
    "for word, i in word_to_idx_inputs.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector = word_to_vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b6002e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2464, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bba3293",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc35d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                              EMBEDDING_DIM,\n",
    "                              weights=[embedding_matrix],\n",
    "                              input_length = max_len_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ccbc0",
   "metadata": {},
   "source": [
    "### One-hot encoded target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc2544",
   "metadata": {},
   "source": [
    "#### Creating targets and since the targets are sequences, I can not use sparse categorical cross entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4893caeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3061\n",
      "26\n",
      "3266\n",
      "(3061, 26)\n"
     ]
    }
   ],
   "source": [
    "print(len(input_texts))\n",
    "print(max_len_outputs)\n",
    "print(num_words_output)\n",
    "print(decoder_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4146da57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets_one_hot = np.zeros((len(input_texts), max_len_outputs, num_words_output), dtype='float32')\n",
    "decoder_targets_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70af32db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3061, 26, 3266)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        if word != 0:\n",
    "            decoder_targets_one_hot[i, t, word] = 1\n",
    "            \n",
    "decoder_targets_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b98a2",
   "metadata": {},
   "source": [
    "### Building a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1997094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dca92a1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Input, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dd760c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_words,\n",
    "                              EMBEDDING_DIM,\n",
    "                              weights=[embedding_matrix],\n",
    "                              input_length = max_len_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c22593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 10:06:42.942958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Setting up encoder\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_inputs,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "\n",
    "encoder = LSTM(LATENT_DIM, return_state=True)\n",
    "\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "encoder_states = [h, c]\n",
    "# print(encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "257d0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up decoder\n",
    "decoder_inputs_placeholder = Input(shape = (max_len_outputs,))\n",
    "decoder_embedding = Embedding(num_words_output, LATENT_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "decoder_lstm = LSTM(LATENT_DIM, return_sequences = True, return_state = True, dropout = 0.5)\n",
    "\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x,\n",
    "                                     initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e9fd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dense layer for prediction\n",
    "decoder_dense = Dense(num_words_output, activation = 'softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ceeb3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "from keras.models import Model\n",
    "\n",
    "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f84e48",
   "metadata": {},
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adc44ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c2aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 18s 382ms/step - loss: 1.7842 - accuracy: 0.0372 - val_loss: 2.7602 - val_accuracy: 0.0385\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 15s 389ms/step - loss: 1.6253 - accuracy: 0.0415 - val_loss: 2.7377 - val_accuracy: 0.0418\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 1.6089 - accuracy: 0.0424 - val_loss: 2.7257 - val_accuracy: 0.0415\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 1.5977 - accuracy: 0.0428 - val_loss: 2.7227 - val_accuracy: 0.0424\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 1.5909 - accuracy: 0.0426 - val_loss: 2.7094 - val_accuracy: 0.0415\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 1.5823 - accuracy: 0.0427 - val_loss: 2.7097 - val_accuracy: 0.0415\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 1.5768 - accuracy: 0.0428 - val_loss: 2.7041 - val_accuracy: 0.0428\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 1.5709 - accuracy: 0.0434 - val_loss: 2.6983 - val_accuracy: 0.0450\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 1.5762 - accuracy: 0.0433 - val_loss: 2.7099 - val_accuracy: 0.0417\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 1.5955 - accuracy: 0.0417 - val_loss: 2.7141 - val_accuracy: 0.0415\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 1.5718 - accuracy: 0.0430 - val_loss: 2.7012 - val_accuracy: 0.0420\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 1.5601 - accuracy: 0.0435 - val_loss: 2.7008 - val_accuracy: 0.0432\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 1.5535 - accuracy: 0.0443 - val_loss: 2.6932 - val_accuracy: 0.0447\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 1.5460 - accuracy: 0.0457 - val_loss: 2.6924 - val_accuracy: 0.0451\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 1.5398 - accuracy: 0.0457 - val_loss: 2.6884 - val_accuracy: 0.0463\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 1.5325 - accuracy: 0.0456 - val_loss: 2.6852 - val_accuracy: 0.0461\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 1.5263 - accuracy: 0.0460 - val_loss: 2.6846 - val_accuracy: 0.0466\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 1.5206 - accuracy: 0.0465 - val_loss: 2.6806 - val_accuracy: 0.0466\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 1.5139 - accuracy: 0.0468 - val_loss: 2.6810 - val_accuracy: 0.0479\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 15s 381ms/step - loss: 1.5078 - accuracy: 0.0474 - val_loss: 2.6775 - val_accuracy: 0.0487\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 1.5006 - accuracy: 0.0482 - val_loss: 2.6772 - val_accuracy: 0.0491\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 1.4933 - accuracy: 0.0489 - val_loss: 2.6722 - val_accuracy: 0.0487\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 1.4861 - accuracy: 0.0493 - val_loss: 2.6697 - val_accuracy: 0.0494\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 1.4779 - accuracy: 0.0503 - val_loss: 2.6692 - val_accuracy: 0.0498\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 1.4715 - accuracy: 0.0508 - val_loss: 2.6690 - val_accuracy: 0.0502\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 13s 336ms/step - loss: 1.4638 - accuracy: 0.0519 - val_loss: 2.6663 - val_accuracy: 0.0508\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 14s 343ms/step - loss: 1.4569 - accuracy: 0.0520 - val_loss: 2.6665 - val_accuracy: 0.0496\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 1.4493 - accuracy: 0.0529 - val_loss: 2.6644 - val_accuracy: 0.0516\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 1.4424 - accuracy: 0.0539 - val_loss: 2.6616 - val_accuracy: 0.0523\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 1.4346 - accuracy: 0.0553 - val_loss: 2.6615 - val_accuracy: 0.0509\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 1.4276 - accuracy: 0.0553 - val_loss: 2.6563 - val_accuracy: 0.0528\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 1.4210 - accuracy: 0.0562 - val_loss: 2.6604 - val_accuracy: 0.0526\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 13s 333ms/step - loss: 1.4139 - accuracy: 0.0564 - val_loss: 2.6591 - val_accuracy: 0.0523\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 1.4066 - accuracy: 0.0576 - val_loss: 2.6525 - val_accuracy: 0.0532\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 1.3977 - accuracy: 0.0585 - val_loss: 2.6527 - val_accuracy: 0.0544\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 1.3898 - accuracy: 0.0594 - val_loss: 2.6487 - val_accuracy: 0.0541\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 1.3840 - accuracy: 0.0604 - val_loss: 2.6498 - val_accuracy: 0.0544\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 15s 399ms/step - loss: 1.3745 - accuracy: 0.0615 - val_loss: 2.6512 - val_accuracy: 0.0541\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 1.3674 - accuracy: 0.0620 - val_loss: 2.6432 - val_accuracy: 0.0564\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 1.3576 - accuracy: 0.0636 - val_loss: 2.6415 - val_accuracy: 0.0563\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 1.3501 - accuracy: 0.0642 - val_loss: 2.6457 - val_accuracy: 0.0568\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 1.3418 - accuracy: 0.0649 - val_loss: 2.6434 - val_accuracy: 0.0565\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 1.3330 - accuracy: 0.0658 - val_loss: 2.6417 - val_accuracy: 0.0568\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 1.3264 - accuracy: 0.0665 - val_loss: 2.6372 - val_accuracy: 0.0566\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 15s 375ms/step - loss: 1.3171 - accuracy: 0.0677 - val_loss: 2.6376 - val_accuracy: 0.0565\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 15s 376ms/step - loss: 1.3082 - accuracy: 0.0688 - val_loss: 2.6383 - val_accuracy: 0.0574\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 15s 371ms/step - loss: 1.3003 - accuracy: 0.0695 - val_loss: 2.6380 - val_accuracy: 0.0579\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 1.2917 - accuracy: 0.0703 - val_loss: 2.6413 - val_accuracy: 0.0574\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 15s 385ms/step - loss: 1.2840 - accuracy: 0.0714 - val_loss: 2.6352 - val_accuracy: 0.0578\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 1.2749 - accuracy: 0.0723 - val_loss: 2.6313 - val_accuracy: 0.0585\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 15s 395ms/step - loss: 1.2666 - accuracy: 0.0733 - val_loss: 2.6336 - val_accuracy: 0.0578\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 1.2589 - accuracy: 0.0734 - val_loss: 2.6344 - val_accuracy: 0.0584\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 1.2493 - accuracy: 0.0755 - val_loss: 2.6356 - val_accuracy: 0.0587\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 1.2423 - accuracy: 0.0756 - val_loss: 2.6358 - val_accuracy: 0.0591\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 1.2339 - accuracy: 0.0770 - val_loss: 2.6317 - val_accuracy: 0.0600\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 1.2254 - accuracy: 0.0773 - val_loss: 2.6282 - val_accuracy: 0.0604\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 14s 350ms/step - loss: 1.2165 - accuracy: 0.0791 - val_loss: 2.6326 - val_accuracy: 0.0617\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 1.2094 - accuracy: 0.0792 - val_loss: 2.6291 - val_accuracy: 0.0604\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 1.2016 - accuracy: 0.0812 - val_loss: 2.6374 - val_accuracy: 0.0590\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 1.1939 - accuracy: 0.0818 - val_loss: 2.6342 - val_accuracy: 0.0609\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 1.1836 - accuracy: 0.0830 - val_loss: 2.6341 - val_accuracy: 0.0616\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 1.1760 - accuracy: 0.0845 - val_loss: 2.6393 - val_accuracy: 0.0612\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 15s 380ms/step - loss: 1.1669 - accuracy: 0.0852 - val_loss: 2.6388 - val_accuracy: 0.0616\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 1.1602 - accuracy: 0.0860 - val_loss: 2.6396 - val_accuracy: 0.0618\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 1.1511 - accuracy: 0.0879 - val_loss: 2.6385 - val_accuracy: 0.0618\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 1.1439 - accuracy: 0.0881 - val_loss: 2.6398 - val_accuracy: 0.0625\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 1.1364 - accuracy: 0.0895 - val_loss: 2.6438 - val_accuracy: 0.0621\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 1.1273 - accuracy: 0.0905 - val_loss: 2.6412 - val_accuracy: 0.0620\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 1.1178 - accuracy: 0.0923 - val_loss: 2.6403 - val_accuracy: 0.0628\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 1.1098 - accuracy: 0.0936 - val_loss: 2.6420 - val_accuracy: 0.0637\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 1.1011 - accuracy: 0.0947 - val_loss: 2.6450 - val_accuracy: 0.0630\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 14s 359ms/step - loss: 1.0944 - accuracy: 0.0953 - val_loss: 2.6462 - val_accuracy: 0.0634\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 1.0856 - accuracy: 0.0974 - val_loss: 2.6468 - val_accuracy: 0.0632\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 1.0796 - accuracy: 0.0982 - val_loss: 2.6437 - val_accuracy: 0.0633\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 1.0706 - accuracy: 0.0990 - val_loss: 2.6516 - val_accuracy: 0.0637\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 1.0641 - accuracy: 0.1000 - val_loss: 2.6551 - val_accuracy: 0.0630\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 1.0555 - accuracy: 0.1017 - val_loss: 2.6439 - val_accuracy: 0.0641\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 16s 418ms/step - loss: 1.0456 - accuracy: 0.1033 - val_loss: 2.6509 - val_accuracy: 0.0648\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 15s 376ms/step - loss: 1.0364 - accuracy: 0.1045 - val_loss: 2.6504 - val_accuracy: 0.0651\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 16s 424ms/step - loss: 1.0243 - accuracy: 0.1069 - val_loss: 2.6514 - val_accuracy: 0.0658\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 1.0161 - accuracy: 0.1079 - val_loss: 2.6521 - val_accuracy: 0.0658\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 1.0084 - accuracy: 0.1101 - val_loss: 2.6548 - val_accuracy: 0.0663\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 0.9996 - accuracy: 0.1114 - val_loss: 2.6585 - val_accuracy: 0.0670\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 14s 366ms/step - loss: 0.9908 - accuracy: 0.1135 - val_loss: 2.6560 - val_accuracy: 0.0651\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 15s 376ms/step - loss: 0.9835 - accuracy: 0.1146 - val_loss: 2.6652 - val_accuracy: 0.0651\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 0.9716 - accuracy: 0.1166 - val_loss: 2.6663 - val_accuracy: 0.0675\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 0.9660 - accuracy: 0.1181 - val_loss: 2.6653 - val_accuracy: 0.0685\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 0.9547 - accuracy: 0.1202 - val_loss: 2.6659 - val_accuracy: 0.0674\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 15s 373ms/step - loss: 0.9461 - accuracy: 0.1212 - val_loss: 2.6640 - val_accuracy: 0.0666\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 15s 395ms/step - loss: 0.9392 - accuracy: 0.1224 - val_loss: 2.6762 - val_accuracy: 0.0687\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 15s 391ms/step - loss: 0.9307 - accuracy: 0.1236 - val_loss: 2.6718 - val_accuracy: 0.0690\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 0.9241 - accuracy: 0.1252 - val_loss: 2.6795 - val_accuracy: 0.0693\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 0.9159 - accuracy: 0.1263 - val_loss: 2.6769 - val_accuracy: 0.0687\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 0.9098 - accuracy: 0.1276 - val_loss: 2.6761 - val_accuracy: 0.0696\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 0.9020 - accuracy: 0.1285 - val_loss: 2.6894 - val_accuracy: 0.0688\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 0.8955 - accuracy: 0.1290 - val_loss: 2.6915 - val_accuracy: 0.0699\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 15s 383ms/step - loss: 0.8894 - accuracy: 0.1301 - val_loss: 2.6941 - val_accuracy: 0.0685\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 15s 376ms/step - loss: 0.8813 - accuracy: 0.1316 - val_loss: 2.6976 - val_accuracy: 0.0694\n",
      "Epoch 99/100\n",
      "14/39 [=========>....................] - ETA: 8s - loss: 0.8716 - accuracy: 0.1328"
     ]
    }
   ],
   "source": [
    "r = model.fit([encoder_inputs, decoder_inputs], \n",
    "          decoder_targets_one_hot,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          epochs = EPOCHS, \n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161cee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r.history['loss'], label = 'loss')\n",
    "plt.plot(r.history['val_loss'], label = 'val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ebe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(r.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5bf15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
